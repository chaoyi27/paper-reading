{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def archive_paper_under_date(filename, title, authors, tags, abstract, link, website_link, affiliation=None, notes=None, teaser_image_path=None, pipeline_image_path=None):\n",
    "    \"\"\"\n",
    "    Archives a paper record in a Markdown file under the current date's first-level header.\n",
    "    If the header for today's date does not exist, it's created.\n",
    "    \"\"\"\n",
    "    current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    header = f\"## {current_date}\\n\\n\"\n",
    "    paper_record = generate_paper_record(title, authors, affiliation, tags, abstract, link, website_link, notes, teaser_image_path, pipeline_image_path)\n",
    "    \n",
    "    try:\n",
    "        with open(filename, \"r+\", encoding=\"utf-8\") as file:\n",
    "            content = file.readlines()\n",
    "            file.seek(0)\n",
    "            if content and content[0].strip() == header.strip():\n",
    "                # If the first header is today's date, archive under this header\n",
    "                content.insert(1, paper_record + \"\\n\")\n",
    "            else:\n",
    "                # Otherwise, prepend today's header and the record\n",
    "                content = [header] + [paper_record + \"\\n\"] + content\n",
    "            file.writelines(content)\n",
    "    except FileNotFoundError:\n",
    "        # If the file does not exist, create it with the header and the record\n",
    "        with open(filename, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(header + paper_record + \"\\n\")\n",
    "\n",
    "def generate_paper_record(\n",
    "    title, authors, affiliation, tags, abstract, link, website_link, notes, \n",
    "    teaser_image_path, pipeline_image_path):\n",
    "    \"\"\"\n",
    "    Generates the Markdown text for a paper record.\n",
    "    \"\"\"\n",
    "    record = f\"### {title}\\n\\n\"\n",
    "    # record += f\"- **Authors**: {', '.join(authors)}\\n\"\n",
    "    # authors is a string, not a list\n",
    "    record += f\"- **Authors**: {authors}\\n\"\n",
    "    if affiliation:\n",
    "        record += f\"- **Main Affiliations**: {', '.join(affiliation)}\\n\"\n",
    "    tags_formatted = ', '.join([f\"`{tag}`\" for tag in tags])\n",
    "    record += f\"- **Tags**: {tags_formatted}\\n\\n\" \n",
    "    \n",
    "    record += f\"#### Abstract\\n\\n{abstract}\\n\\n\"\n",
    "    record += f\"[Paper Link]({link})\\n\\n\"\n",
    "    \n",
    "    if teaser_image_path:\n",
    "        # record += f\"![Teaser Image]({teaser_image_path})\\n\\n\"\n",
    "        '''\n",
    "        use the formate as below\n",
    "        <div style={{ display: 'flex', justifyContent: 'center' }}>\n",
    "        <div style={{ textAlign: 'center', marginRight: '10px' }}>\n",
    "            <img src=\"/img/daily/2024-04-04_17-52.png\" alt=\"SAPIEN Rendering\" style={{ width: 'auto', maxHeight: '600px' }} />\n",
    "            <p>SAPIEN</p>\n",
    "        </div>\n",
    "        </div>\n",
    "        '''\n",
    "        record += \"<div style={{ display: 'flex', justifyContent: 'center' }}>\\n\"\n",
    "        record += \"<div style={{ textAlign: 'center', marginRight: '10px' }}>\\n\"\n",
    "        record += f\"<img src=\\\"{teaser_image_path}\\\" alt=\\\"img\\\" style={{{{ width: 'auto', maxHeight: '600px' }}}} />\\n\"\n",
    "        record += \"</div>\\n\"\n",
    "        record += \"</div>\\n\\n\"\n",
    "        \n",
    "    if pipeline_image_path:\n",
    "        # record += f\"![Pipeline Image]({pipeline_image_path})\\n\\n\" \n",
    "        record += \"<div style={{ display: 'flex', justifyContent: 'center' }}>\\n\"\n",
    "        record += \"<div style={{ textAlign: 'center', marginRight: '10px' }}>\\n\"\n",
    "        record += f\"<img src=\\\"{pipeline_image_path}\\\" alt=\\\"{title}\\\" style={{{{ width: 'auto', maxHeight: '600px' }}}} />\\n\"\n",
    "        record += \"</div>\\n\"\n",
    "        record += \"</div>\\n\\n\"\n",
    "    \n",
    "    if website_link != \"Project website not found\":\n",
    "        record += f\"[Website Link]({website_link})\\n\\n\"\n",
    "    \n",
    "    # if the notes is not a none, add a notes section\n",
    "    if notes:\n",
    "        record += f\"#### Notes\\n\\n{notes}\\n\\n\"\n",
    "    \n",
    "    # add a horizontal line\n",
    "    record += \"---\\n\\n\"\n",
    "    \n",
    "    return record\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def fetch_paper_details(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Extract the paper title\n",
    "        title_element = soup.find('h1', class_='title mathjax')\n",
    "        title = title_element.text.replace('\\n', '').strip() if title_element else 'Title not found'\n",
    "        # move the \"Title\"\n",
    "        title = title.replace(\"Title:\", \"\").strip()\n",
    "\n",
    "        # Extract the author information\n",
    "        authors_element = soup.find('div', class_='authors')\n",
    "        authors = authors_element.text.replace('\\n', ' ').replace('Authors:', '').strip() if authors_element else 'Authors not found'\n",
    "\n",
    "        # Extract the abstract\n",
    "        abstract_element = soup.find('blockquote', class_='abstract mathjax')\n",
    "        abstract = abstract_element.text.replace('\\n', ' ').replace('Abstract:  ', '').strip() if abstract_element else 'Abstract not found'\n",
    "        # move the \"Abstract\"\n",
    "        abstract = abstract.replace(\"Abstract:\", \"\").strip()\n",
    "\n",
    "        # Extract the project website URL\n",
    "        project_website_element = soup.find('a', href=lambda href: href and \"leg-manip\" in href)\n",
    "        project_website_url = project_website_element['href'] if project_website_element else \"Project website not found\"\n",
    "\n",
    "        return title, authors, abstract, project_website_url\n",
    "        # return {\n",
    "        #     'Title': title,\n",
    "        #     'Authors': authors,\n",
    "        #     'Abstract': abstract,\n",
    "        #     'Project Website URL': project_website_url\n",
    "        # }\n",
    "    except Exception as e:\n",
    "        return {'Error': f'Failed to fetch details due to {e}'}\n",
    "\n",
    "# # Example usage\n",
    "# url = 'https://arxiv.org/abs/2403.20328'\n",
    "# paper_details = fetch_paper_details(url)\n",
    "# for key, value in paper_details.items():\n",
    "#     print(f'{key}: {value}')\n",
    "\n",
    "# url = 'https://arxiv.org/abs/2403.20328'\n",
    "# title, authors, abstract, project_website_url = fetch_paper_details(url)\n",
    "# print(title)\n",
    "# print(authors)\n",
    "# print(abstract)\n",
    "# print(project_website_url)\n",
    "\n",
    "from types import SimpleNamespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = SimpleNamespace(\n",
    "    nav=\"Navigation\",\n",
    "    mm=\"Mobile Manipulation\",\n",
    "    s2r=\"Simulation to Reality\",\n",
    "    s=\"Simulation\",\n",
    "    il=\"Imitation Learning\",\n",
    "    bc=\"Behavioral Cloning\",\n",
    "    rl=\"Reinforcement Learning\",\n",
    "    survey=\"Survey\",\n",
    "    llm=\"Large Language Models\",\n",
    "    nerf=\"NeRF\",\n",
    "    m=\"Manipulation\",\n",
    "    tamp=\"TAMP\",\n",
    ")\n",
    "unis = SimpleNamespace(\n",
    "    MIT=\"Massachusetts Institute of Technology\",\n",
    "    Stanford=\"Stanford University\",\n",
    "    CMU=\"Carnegie Mellon University\",\n",
    "    UCB=\"University of California, Berkeley\",\n",
    "    Harvard=\"Harvard University\",\n",
    "    Oxford=\"University of Oxford\",\n",
    "    Cambridge=\"University of Cambridge\",\n",
    "    ETH=\"Robotic Systems Lab-ETH Zurich\",\n",
    "    # ETH=\"Robot ETH Zurich\",\n",
    "    Imperial=\"Imperial College London\",\n",
    "    Tsinghua=\"Tsinghua University\",\n",
    "    iiis=\"IIIS, Tsinghua University\",\n",
    "    PKU=\"Peking University\",\n",
    "    TUM=\"Technical University of Munich\",\n",
    "    HKUST=\"Hong Kong University of Science and Technology\",\n",
    "    CUHK=\"Chinese University of Hong Kong\",\n",
    "    git=\"Georgia Institute of Technology\",\n",
    ")\n",
    "ins = SimpleNamespace(\n",
    "    DeepMind=\"Google DeepMind\",\n",
    "    OpenAI=\"OpenAI\",\n",
    "    FAIR=\"Facebook AI Research\",\n",
    "    MSR=\"Microsoft Research\",\n",
    "    IBM=\"IBM Research\",\n",
    "    NVIDIA=\"NVIDIA Research\",\n",
    "    ShanghaiQizhi=\"Shanghai Qizhi Institute\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 粘贴link\n",
    "# 2. 输入affiliation\n",
    "# 3. 输入tags\n",
    "# 4. 输入notes (是否有，没有的话注释)\n",
    "# 5. 输入teaser_image_path (是否有，没有的话注释)\n",
    "# 6. 输入pipeline_image_path (是否有，没有的话注释)\n",
    "# npm start \n",
    "\n",
    "link=\"https://arxiv.org/abs/2404.02569\"\n",
    "affiliation=[\"OMRON SINIC X Corporation\"]\n",
    "t=[tags.s2r]\n",
    "notes=\"These are the notes.\"\n",
    "teaser_image_path=\"/static/img/daily/2024-04-04_17-42.png\"\n",
    "pipeline_image_path=\"/static/img/daily/2024-04-04_17-52.png\"\n",
    "# cut the \"/static\" part of the paths\n",
    "teaser_image_path = teaser_image_path[7:]\n",
    "pipeline_image_path = pipeline_image_path[7:]\n",
    "\n",
    "title, authors, abstract, project_website_url = fetch_paper_details(link)\n",
    "archive_paper_under_date(\n",
    "    filename=\"src/pages/daily/daily.md\",\n",
    "    title=title,authors=authors,tags=t,abstract=abstract,link=link,website_link=project_website_url,\n",
    "    \n",
    "    affiliation=affiliation,\n",
    "    # notes=notes,\n",
    "    teaser_image_path=teaser_image_path,\n",
    "    # pipeline_image_path=pipeline_image_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ins' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m link\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://arxiv.org/abs/2403.20328\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m affiliation\u001b[38;5;241m=\u001b[39m[\u001b[43mins\u001b[49m\u001b[38;5;241m.\u001b[39mShanghaiQizhi, unis\u001b[38;5;241m.\u001b[39mHKUST, unis\u001b[38;5;241m.\u001b[39mCMU, unis\u001b[38;5;241m.\u001b[39miiis]\n\u001b[1;32m      4\u001b[0m t\u001b[38;5;241m=\u001b[39m[tags\u001b[38;5;241m.\u001b[39mrl, tags\u001b[38;5;241m.\u001b[39mbc, tags\u001b[38;5;241m.\u001b[39mmm]\n\u001b[1;32m      6\u001b[0m notes\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThese are the notes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ins' is not defined"
     ]
    }
   ],
   "source": [
    "link=\"https://arxiv.org/abs/2403.20328\"\n",
    "\n",
    "affiliation=[ins.ShanghaiQizhi, unis.HKUST, unis.CMU, unis.iiis]\n",
    "t=[tags.rl, tags.bc, tags.mm]\n",
    "\n",
    "notes=\"These are the notes.\"\n",
    "teaser_image_path=\"../imgs/2024-04-04_00-30.png\"\n",
    "pipeline_image_path=\"../imgs/2024-04-04_00-30_1.png\"\n",
    "\n",
    "\n",
    "link=\"https://arxiv.org/abs/2403.19916\"\n",
    "\n",
    "affiliation=[unis.CUHK, unis.TUM]\n",
    "t=[tags.review, tags.il]\n",
    "\n",
    "notes=\"These are the notes.\"\n",
    "teaser_image_path=\"../imgs/2024-04-04_00-30.png\"\n",
    "pipeline_image_path=\"../imgs/2024-04-04_00-30_1.png\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/img/daily/2024-04-04_17-42.png'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teaser_image_path=\"/static/img/daily/2024-04-04_17-42.png\"\n",
    "pipeline_image_path=\"/static/img/daily/2024-04-04_17-52.png\"\n",
    "# cut the \"/static\" part of the paths\n",
    "teaser_image_path = teaser_image_path[7:]\n",
    "teaser_image_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
